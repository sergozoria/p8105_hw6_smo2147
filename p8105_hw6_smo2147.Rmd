---
title: "Homework 6"
author: "Sergio Ozoria Ramirez"
date: "2025-12-01"
output: github_document
---


# Set up
Potential packages are first loaded to use for our problem sets. Figure
preferences were used to set figure sizing and aesthetics for plotting
outputs.

```{r setup}
library(tidyverse)
library(gtsummary)
library(modelr)
library(rvest)
library(scales)
library(p8105.datasets)
library(broom)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

```{r loading dataset}
wash_homi =
  read.csv("./Data/homicide-data.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names()
```

```{r create_city_state_and_filters}
wash_homi = 
  wash_homi |>
  mutate(
    city_state = str_c(city, state, sep = ", "),
    solved = factor(case_when(
      disposition == "Closed by arrest" ~ "Solved",
      disposition %in% c("Closed without arrest", "Open/No arrest") ~ "Unsolved"
    ),
    levels = c("Unsolved", "Solved")
    )
  ) |> 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                       "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |> 
  mutate(
    victim_age = as.numeric(victim_age)
  )
```

```{r baltimore logistic regression}
baltimore_df = wash_homi |> 
  filter(city_state == "Baltimore, MD")

baltimore_lg = glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_df,
  family = binomial
)

baltimore_tidy = 
  tidy(
    baltimore_lg,
    exponentiate = TRUE,
    conf.int = TRUE)

knitr::kable(baltimore_tidy)

baltimore_tidy |> 
  filter(term == "victim_sexMale") |> 
  knitr::kable()
```

```{r all cities log regression}
all_cities = wash_homi |> 
  group_by(city_state) |> 
  nest() |> 
  mutate(
    model = map(data, ~ glm(
      solved ~ victim_age + victim_sex + victim_race,
      data = .x,
      family = binomial
    )),
    tidied = map(model, ~ tidy(
      .x,
      exponentiate = TRUE,
      conf.int = TRUE
    ))
  ) |> 
  unnest(tidied) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, estimate, conf.low, conf.high, p.value)

all_cities_plot =
  all_cities |>
  arrange(estimate)

knitr::kable(all_cities_plot)
```


```{r figure_1, fig.height = 22, fig.width = 7}
ggplot(all_cities_plot,
       aes(
         x = estimate,
         y = fct_reorder(city_state, estimate)
       )) +
  geom_point(size = 2) +
  geom_errorbar(
    aes(xmin = conf.low, xmax = conf.high,
        y = fct_reorder(city_state, estimate)),
    width = 0.2,
    orientation = "y"
  ) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  labs(
    title = "Figure 1. Adjusted Odds Ratios: Male vs Female Homicide Victims (U.S. Cities)",
    x = "Adjusted ORs (Male vs Female)",
    y = "City"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.y = element_text(size = 7),
    plot.title = element_text(size = 16, hjust = 0.5)
  )
```

#### Figure 1. Comments:

Across U.S. cities in our sample, the adjusted odds ratios were predominantly below the null value of 1, indicating that homicides involving male victims were less likely to be solved when compared to those involving female victims, after adjusting for victim age and race. In many cities, however, the confidence intervals included the null value, suggesting little evidence of an association and/or no clear indication of higher or lower case resolution rates for male-victim case in those cities. 

For example, New York, NY had an adjusted OR of approximately 0.24-0.26, with narrow confidence interval estimates that did not include the null value of 1. This suggests there is a strong association that homicide cases involving male victims in NYC had lower odds of being solved when compared to cases involving female victims in the same city, after adjusting for key covariates. 

On the flip-side, Albuquerque, NM had an adjusted OR of approximately 1.75-1.80, with large confidence interval estimates, including the null value of 1. This suggests there is not a strong association that homicide cases involving males in Albuquerque were more or less likely to be solved when compared to those involving female victims in the same city, after adjusting for key predictors.

# Problem 2

```{r loading p2 dataset}
library(p8105.datasets)
data("weather_df") 

weather_clean = weather_df |>
  select(tmax, tmin, prcp) |>
  drop_na()
```

```{r bootstrap funct} 
bootstrap_est = function(df) {
  
  boot_df = sample_frac(df, replace = TRUE)
  
  fit = lm(tmax ~ tmin + prcp, data = boot_df)
  
  r2 = glance(fit) |> 
    pull(r.squared)
  
  coef_df = tidy(fit)
  
  beta1 =
    coef_df |> 
    filter(term == "tmin") |> 
    pull(estimate)
  
  beta2 =
    coef_df |> 
    filter(term == "prcp") |> 
    pull(estimate)

  tibble(
    r2 = r2,
    beta_ratio = beta1 / beta2
  )
}
```


```{r iteraton 5000}
set.seed(123)

boot_results =
  tibble(iter = 1:5000) |> 
  mutate(
    results = map(iter, ~ bootstrap_est(weather_clean)
  )) |> 
    unnest(results)
```


```{r figure 2}
boot_results |> 
  ggplot(aes(x = r2)) +
  geom_histogram(bins = 40, fill = "skyblue", color = "white") +
  labs(
    title = "Figure 2. Bootstrap Distribution of R2",
    x = "R2",
    y = "Count"
  )

boot_ci_r2 = boot_results |> 
  summarize(
    lower = quantile(r2, 0.025),
    upper = quantile(r2, 0.975)
  )

boot_ci_r2 |> 
  knitr::kable()
```

#### Figure 2. Comments: 

The bootstrap distribution of R2 is approximately symmetric and bell-shaped, where the data is centered around 0.94. This means that across repeated resamples of the weather data, the model will consistently explain about 94% of the variability in `tmax` using `tmin` and `prcp` as predictors. The remaining 6% of variation might be explain by outside factors not included in the model, which could reflect day-to-day fluctuations in temperature that are not captured by our predictors. Therefore, with bootstrap sample of 5000, the 95% CI for R2 is about 0.934 (lower), 0.946 (upper). These estimates show little uncertainty in the statistical power the model is producing. Thus, we can conclude that tmin is a strong predictor of tmax. 

```{r figure 3}
boot_results |> 
  ggplot(aes(x = beta_ratio)) +
  geom_histogram(bins = 40, fill = "orchid", color = "white") +
  labs(
    title = "Figure 3. Bootstrap Distribution of B1 / B2",
    x = expression(hat(beta)[1] / hat(beta)[2]),
    y = "Count"
  )

boot_ci_b12 = boot_results |> 
  summarize(
    lower = quantile(beta_ratio, 0.025),
    upper = quantile(beta_ratio, 0.975)
  )

boot_ci_b12 |> 
  knitr::kable()
```

#### Figure 3. Comments:

The bootstrap distribution for B1 and B2 is right-skewed and centered around large negative values, somewhere between 280 and 120. This means that the estimated coefficients for `prcp` are very close to zero across most bootstrap samples. Because of this, it leads to instability in the model and long tails in the distribution. This is also supported by the 95% bootstrap CIs for the estimates, with a 95% CI of -277.17 (lower), -125.70 (upper), showing instability. This means that `tmin` and `prcp` have opposite estimates in almost most bootstrap samples. This means that `prcp` is unable to provide linear information once we account for `tmin` in the model