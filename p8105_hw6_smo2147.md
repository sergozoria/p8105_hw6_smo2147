Homework 6
================
Sergio Ozoria Ramirez
2025-12-01

# Set up

Potential packages are first loaded to use for our problem sets. Figure
preferences were used to set figure sizing and aesthetics for plotting
outputs.

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.1     ✔ stringr   1.6.0
    ## ✔ ggplot2   4.0.0     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.2.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(gtsummary)
library(modelr)
library(rvest)
```

    ## 
    ## Attaching package: 'rvest'
    ## 
    ## The following object is masked from 'package:readr':
    ## 
    ##     guess_encoding

``` r
library(scales)
```

    ## 
    ## Attaching package: 'scales'
    ## 
    ## The following object is masked from 'package:purrr':
    ## 
    ##     discard
    ## 
    ## The following object is masked from 'package:readr':
    ## 
    ##     col_factor

``` r
library(p8105.datasets)
library(broom)
```

    ## 
    ## Attaching package: 'broom'
    ## 
    ## The following object is masked from 'package:modelr':
    ## 
    ##     bootstrap

``` r
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

``` r
wash_homi =
  read.csv("./Data/homicide-data.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names()
```

``` r
wash_homi = 
  wash_homi |>
  mutate(
    city_state = str_c(city, state, sep = ", "),
    solved = factor(case_when(
      disposition == "Closed by arrest" ~ "Solved",
      disposition %in% c("Closed without arrest", "Open/No arrest") ~ "Unsolved"
    ),
    levels = c("Unsolved", "Solved")
    )
  ) |> 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                       "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |> 
  mutate(
    victim_age = as.numeric(victim_age)
  )
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `victim_age = as.numeric(victim_age)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

``` r
baltimore_df = wash_homi |> 
  filter(city_state == "Baltimore, MD")

baltimore_lg = glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_df,
  family = binomial
)

baltimore_tidy = 
  tidy(
    baltimore_lg,
    exponentiate = TRUE,
    conf.int = TRUE)

knitr::kable(baltimore_tidy)
```

| term             |  estimate | std.error | statistic |   p.value |  conf.low | conf.high |
|:-----------------|----------:|----------:|----------:|----------:|----------:|----------:|
| (Intercept)      | 1.3633992 | 0.1712948 |  1.809635 | 0.0703525 | 0.9757573 | 1.9107826 |
| victim_age       | 0.9932953 | 0.0033235 | -2.024124 | 0.0429574 | 0.9868059 | 0.9997539 |
| victim_sexMale   | 0.4255117 | 0.1381762 | -6.183864 | 0.0000000 | 0.3241908 | 0.5575508 |
| victim_raceWhite | 2.3204389 | 0.1747162 |  4.817851 | 0.0000015 | 1.6496269 | 3.2759334 |

``` r
baltimore_tidy |> 
  filter(term == "victim_sexMale") |> 
  knitr::kable()
```

| term           |  estimate | std.error | statistic | p.value |  conf.low | conf.high |
|:---------------|----------:|----------:|----------:|--------:|----------:|----------:|
| victim_sexMale | 0.4255117 | 0.1381762 | -6.183864 |       0 | 0.3241908 | 0.5575508 |

``` r
all_cities = wash_homi |> 
  group_by(city_state) |> 
  nest() |> 
  mutate(
    model = map(data, ~ glm(
      solved ~ victim_age + victim_sex + victim_race,
      data = .x,
      family = binomial
    )),
    tidied = map(model, ~ tidy(
      .x,
      exponentiate = TRUE,
      conf.int = TRUE
    ))
  ) |> 
  unnest(tidied) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, estimate, conf.low, conf.high, p.value)
```

    ## Warning: There were 43 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `tidied = map(model, ~tidy(.x, exponentiate = TRUE, conf.int =
    ##   TRUE))`.
    ## ℹ In group 1: `city_state = "Albuquerque, NM"`.
    ## Caused by warning:
    ## ! glm.fit: fitted probabilities numerically 0 or 1 occurred
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 42 remaining warnings.

``` r
all_cities_plot =
  all_cities |>
  arrange(estimate)

knitr::kable(all_cities_plot)
```

| city_state         |  estimate |  conf.low | conf.high |   p.value |
|:-------------------|----------:|----------:|----------:|----------:|
| New York, NY       | 0.2623978 | 0.1327512 | 0.4850117 | 0.0000454 |
| Baton Rouge, LA    | 0.3814393 | 0.2043481 | 0.6836343 | 0.0016535 |
| Omaha, NE          | 0.3824861 | 0.1988357 | 0.7109316 | 0.0029514 |
| Cincinnati, OH     | 0.3998277 | 0.2313767 | 0.6670456 | 0.0006485 |
| Chicago, IL        | 0.4100982 | 0.3361233 | 0.5008546 | 0.0000000 |
| Long Beach, CA     | 0.4102163 | 0.1427304 | 1.0241775 | 0.0717631 |
| San Diego, CA      | 0.4130248 | 0.1913527 | 0.8301847 | 0.0172175 |
| Baltimore, MD      | 0.4255117 | 0.3241908 | 0.5575508 | 0.0000000 |
| Pittsburgh, PA     | 0.4307528 | 0.2626022 | 0.6955518 | 0.0006724 |
| Denver, CO         | 0.4790620 | 0.2327380 | 0.9624974 | 0.0410964 |
| Louisville, KY     | 0.4905546 | 0.3014879 | 0.7836391 | 0.0033700 |
| Philadelphia, PA   | 0.4962756 | 0.3760120 | 0.6498797 | 0.0000005 |
| San Bernardino, CA | 0.5003444 | 0.1655367 | 1.4623977 | 0.2056661 |
| Miami, FL          | 0.5152379 | 0.3040214 | 0.8734480 | 0.0134772 |
| Buffalo, NY        | 0.5205704 | 0.2884416 | 0.9358300 | 0.0289521 |
| Columbus, OH       | 0.5324845 | 0.3770457 | 0.7479124 | 0.0003039 |
| Oakland, CA        | 0.5630819 | 0.3637421 | 0.8671086 | 0.0093743 |
| Detroit, MI        | 0.5823472 | 0.4619454 | 0.7335458 | 0.0000045 |
| New Orleans, LA    | 0.5849373 | 0.4218807 | 0.8121787 | 0.0013105 |
| San Francisco, CA  | 0.6075362 | 0.3116925 | 1.1551470 | 0.1336164 |
| Los Angeles, CA    | 0.6618816 | 0.4565014 | 0.9541036 | 0.0279274 |
| Sacramento, CA     | 0.6688418 | 0.3262733 | 1.3143888 | 0.2548059 |
| Fort Worth, TX     | 0.6689803 | 0.3935128 | 1.1211603 | 0.1311687 |
| Boston, MA         | 0.6739912 | 0.3534469 | 1.2768225 | 0.2256969 |
| Washington, DC     | 0.6901713 | 0.4653608 | 1.0122516 | 0.0608080 |
| St. Louis, MO      | 0.7031665 | 0.5298505 | 0.9319005 | 0.0143877 |
| San Antonio, TX    | 0.7046200 | 0.3928179 | 1.2382509 | 0.2303369 |
| Houston, TX        | 0.7110264 | 0.5569844 | 0.9057376 | 0.0059322 |
| Jacksonville, FL   | 0.7198144 | 0.5359236 | 0.9650986 | 0.0283233 |
| Memphis, TN        | 0.7232194 | 0.5261210 | 0.9835973 | 0.0420463 |
| Milwaukee, wI      | 0.7271327 | 0.4951325 | 1.0542297 | 0.0976722 |
| Tampa, FL          | 0.8077029 | 0.3395253 | 1.8598834 | 0.6193928 |
| Durham, NC         | 0.8123514 | 0.3824420 | 1.6580169 | 0.5761077 |
| Las Vegas, NV      | 0.8373078 | 0.6058830 | 1.1510854 | 0.2776086 |
| Savannah, GA       | 0.8669817 | 0.4185827 | 1.7802453 | 0.6973523 |
| Birmingham, AL     | 0.8700153 | 0.5713814 | 1.3138409 | 0.5111455 |
| Charlotte, NC      | 0.8838976 | 0.5507440 | 1.3905954 | 0.6004077 |
| Indianapolis, IN   | 0.9187284 | 0.6784616 | 1.2413059 | 0.5818930 |
| Minneapolis, MN    | 0.9469587 | 0.4759016 | 1.8809745 | 0.8757279 |
| Oklahoma City, OK  | 0.9740747 | 0.6228507 | 1.5199721 | 0.9079362 |
| Tulsa, OK          | 0.9757694 | 0.6090664 | 1.5439356 | 0.9174584 |
| Atlanta, GA        | 1.0000771 | 0.6803477 | 1.4582575 | 0.9996829 |
| Richmond, VA       | 1.0060520 | 0.4834671 | 1.9936248 | 0.9865837 |
| Nashville, TN      | 1.0342379 | 0.6807452 | 1.5559966 | 0.8728884 |
| Fresno, CA         | 1.3351647 | 0.5672553 | 3.0475080 | 0.4963822 |
| Stockton, CA       | 1.3517273 | 0.6256427 | 2.9941299 | 0.4474507 |
| Albuquerque, NM    | 1.7674995 | 0.8247081 | 3.7618600 | 0.1392989 |

``` r
ggplot(all_cities_plot,
       aes(
         x = estimate,
         y = fct_reorder(city_state, estimate)
       )) +
  geom_point(size = 2) +
  geom_errorbar(
    aes(xmin = conf.low, xmax = conf.high,
        y = fct_reorder(city_state, estimate)),
    width = 0.2,
    orientation = "y"
  ) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  labs(
    title = "Figure 1. Adjusted Odds Ratios: Male vs Female Homicide Victims (U.S. Cities)",
    x = "Adjusted ORs (Male vs Female)",
    y = "City"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.y = element_text(size = 7),
    plot.title = element_text(size = 16, hjust = 0.5)
  )
```

<img src="p8105_hw6_smo2147_files/figure-gfm/figure_1-1.png" width="90%" />

#### Figure 1. Comments:

Across U.S. cities in our sample, the adjusted odds ratios were
predominantly below the null value of 1, indicating that homicides
involving male victims were less likely to be solved when compared to
those involving female victims, after adjusting for victim age and race.
In many cities, however, the confidence intervals included the null
value, suggesting little evidence of an association and/or no clear
indication of higher or lower case resolution rates for male-victim case
in those cities.

For example, New York, NY had an adjusted OR of approximately 0.24-0.26,
with narrow confidence interval estimates that did not include the null
value of 1. This suggests there is a strong association that homicide
cases involving male victims in NYC had lower odds of being solved when
compared to cases involving female victims in the same city, after
adjusting for key covariates.

On the flip-side, Albuquerque, NM had an adjusted OR of approximately
1.75-1.80, with large confidence interval estimates, including the null
value of 1. This suggests there is not a strong association that
homicide cases involving males in Albuquerque were more or less likely
to be solved when compared to those involving female victims in the same
city, after adjusting for key predictors.

# Problem 2

``` r
library(p8105.datasets)
data("weather_df") 

weather_clean = weather_df |>
  select(tmax, tmin, prcp) |>
  drop_na()
```

``` r
bootstrap_est = function(df) {
  
  boot_df = sample_frac(df, replace = TRUE)
  
  fit = lm(tmax ~ tmin + prcp, data = boot_df)
  
  r2 = glance(fit) |> 
    pull(r.squared)
  
  coef_df = tidy(fit)
  
  beta1 =
    coef_df |> 
    filter(term == "tmin") |> 
    pull(estimate)
  
  beta2 =
    coef_df |> 
    filter(term == "prcp") |> 
    pull(estimate)

  tibble(
    r2 = r2,
    beta_ratio = beta1 / beta2
  )
}
```

``` r
set.seed(123)

boot_results =
  tibble(iter = 1:5000) |> 
  mutate(
    results = map(iter, ~ bootstrap_est(weather_clean)
  )) |> 
    unnest(results)
```

``` r
boot_results |> 
  ggplot(aes(x = r2)) +
  geom_histogram(bins = 40, fill = "skyblue", color = "white") +
  labs(
    title = "Figure 2. Bootstrap Distribution of R2",
    x = "R2",
    y = "Count"
  )
```

<img src="p8105_hw6_smo2147_files/figure-gfm/figure 2-1.png" width="90%" />

``` r
boot_ci_r2 = boot_results |> 
  summarize(
    lower = quantile(r2, 0.025),
    upper = quantile(r2, 0.975)
  )

boot_ci_r2 |> 
  knitr::kable()
```

|    lower |     upper |
|---------:|----------:|
| 0.934389 | 0.9466496 |

#### Figure 2. Comments:

The bootstrap distribution of R2 is approximately symmetric and
bell-shaped, where the data is centered around 0.94. This means that
across repeated resamples of the weather data, the model will
consistently explain about 94% of the variability in `tmax` using `tmin`
and `prcp` as predictors. The remaining 6% of variation might be explain
by outside factors not included in the model, which could reflect
day-to-day fluctuations in temperature that are not captured by our
predictors. Therefore, with bootstrap sample of 5000, the 95% CI for R2
is about 0.934 (lower), 0.946 (upper). These estimates show little
uncertainty in the statistical power the model is producing. Thus, we
can conclude that tmin is a strong predictor of tmax.

``` r
boot_results |> 
  ggplot(aes(x = beta_ratio)) +
  geom_histogram(bins = 40, fill = "orchid", color = "white") +
  labs(
    title = "Figure 3. Bootstrap Distribution of B1 / B2",
    x = expression(hat(beta)[1] / hat(beta)[2]),
    y = "Count"
  )
```

<img src="p8105_hw6_smo2147_files/figure-gfm/figure 3-1.png" width="90%" />

``` r
boot_ci_b12 = boot_results |> 
  summarize(
    lower = quantile(beta_ratio, 0.025),
    upper = quantile(beta_ratio, 0.975)
  )

boot_ci_b12 |> 
  knitr::kable()
```

|     lower |     upper |
|----------:|----------:|
| -277.1703 | -125.7063 |

#### Figure 3. Comments:

The bootstrap distribution for B1 and B2 is right-skewed and centered
around large negative values, somewhere between 280 and 120. This means
that the estimated coefficients for `prcp` are very close to zero across
most bootstrap samples. Because of this, it leads to instability in the
model and long tails in the distribution. This is also supported by the
95% bootstrap CIs for the estimates, with a 95% CI of -277.17 (lower),
-125.70 (upper), showing instability. This means that `tmin` and `prcp`
have opposite estimates in almost most bootstrap samples. This means
that `prcp` is unable to provide linear information once we account for
`tmin` in the mode

# Problem 3

``` r
birthweight = 
  read_csv("./Data/birthweight.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names()
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
birthweight = birthweight |> 
mutate(
    babysex = factor(
      babysex,
      levels = c(1, 2),
      labels = c("Male", "Female")
    ),
    frace = factor(
      frace,
      levels = c(1, 2, 3, 4, 8, 9),
      labels = c("White", "Black", "Asian", 
                 "Puerto Rican", "Other", "Unknown")
    ),
    mrace = factor(
      mrace,
      levels = c(1, 2, 3, 4, 8),
      labels = c("White", "Black", "Asian", 
                 "Puerto Rican", "Other")
    ),
    parity = as.integer(parity),
    pnumlbw = as.integer(pnumlbw),
    pnumsga = as.integer(pnumsga),
    malform = factor(
      malform, 
      levels = c(0, 1),
      labels = c("Absent", "Present"))
  )
```

``` r
colSums(is.na(birthweight)) |> 
  knitr::kable()
```

|          |   x |
|:---------|----:|
| babysex  |   0 |
| bhead    |   0 |
| blength  |   0 |
| bwt      |   0 |
| delwt    |   0 |
| fincome  |   0 |
| frace    |   0 |
| gaweeks  |   0 |
| malform  |   0 |
| menarche |   0 |
| mheight  |   0 |
| momage   |   0 |
| mrace    |   0 |
| parity   |   0 |
| pnumlbw  |   0 |
| pnumsga  |   0 |
| ppbmi    |   0 |
| ppwt     |   0 |
| smoken   |   0 |
| wtgain   |   0 |

### Birthweight Regression Model

To propose a regression model for the birth-weight dataset, I took a
look at the dataset in question, explored the literature a bit, and
considered biological factors into the decision-making for this
regression model. Because birth-weight is impacted by the head
circumference and length at birth (which tend to be larger/heavier than
the body at birth), as well as the mother’s gestational age, these
variables serve as core indicators of fetal growth. There are also other
factors known to impact fetal growth, such as smoking during pregnancy,
maternal weight gain, pre-pregnancy body mass index, and the age of the
mother.

Based on these factors, I used a linear regression model that includes
`bhead` as the main predictor and `bwt` as the outcome of interest,
followed by additional covariates, including `blength`, `gaweeks`,
`babysex`, `smoken`, `wtgain`, `ppbmi`, `mheight`, and `momage`. These
covariates help reduce potential confounding and improve
precision/accuracy in our estimates.

This model will be compared to another model that uses length at birth
and gestational age as predictors, and another that includes head
circumference, length, sex, and all interactions. These models will help
us assess which model is the best at predicting the outcomes of
interest.

``` r
bw_model1 = lm(
  bwt ~ bhead + blength + gaweeks + babysex + 
    smoken + wtgain + ppbmi + mheight + momage,
  data = birthweight
)

bw_model1 |> 
  broom::tidy() |> 
  knitr::kable()
```

| term          |     estimate |   std.error |  statistic |   p.value |
|:--------------|-------------:|------------:|-----------:|----------:|
| (Intercept)   | -6981.246285 | 134.3226154 | -51.973722 | 0.0000000 |
| bhead         |   135.475979 |   3.5091350 |  38.606659 | 0.0000000 |
| blength       |    77.412532 |   2.0606831 |  37.566441 | 0.0000000 |
| gaweeks       |    12.898217 |   1.4917252 |   8.646510 | 0.0000000 |
| babysexFemale |    31.378541 |   8.6563793 |   3.624904 | 0.0002924 |
| smoken        |    -2.617612 |   0.5791088 |  -4.520068 | 0.0000063 |
| wtgain        |     3.989200 |   0.4033096 |   9.891161 | 0.0000000 |
| ppbmi         |     5.939580 |   1.3618064 |   4.361546 | 0.0000132 |
| mheight       |    13.010482 |   1.6416660 |   7.925170 | 0.0000000 |
| momage        |     6.415383 |   1.1225980 |   5.714764 | 0.0000000 |

#### Residual and Fitted Values Plot

``` r
bwt_plot = birthweight |> 
  add_predictions(bw_model1) |> 
  add_residuals(bw_model1)

ggplot(bwt_plot, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs. Fitted Plot for Birthweight Model",
    x = "Fitted (Predicted)",
    y = "Residuals"
  ) +
  theme_minimal()
```

<img src="p8105_hw6_smo2147_files/figure-gfm/residual and fitted values plot-1.png" width="90%" />

#### 
